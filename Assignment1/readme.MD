# Assignment1

1. Comparison of Different Depth of Networks
2. Comparison of Different Width of Layers
3. Comparison of Different Loss Functions
4. Comparison of Different Activation Functions


## 1. Problem Setup
1. Default Depth : 3
2. Default Width : 512
3. Default Loss Function : categorical_crossentropy [(More detail)](https://keras.io/losses/#categorical_crossentropy)
4. Default Activation Function : ReLU [(More detail)](https://keras.io/activations/#relu)
5. MNIST Dataset
6. Fixed Optimizer = 'rmsprop' (and Default parameters [(see)](https://keras.io/optimizers/#rmsprop))
7. Fixed epochs = '10'
8. Fixed batch_size = '128'
9. Fixed validation_split = '0.1'

## 2. Experiment
## 2.1 Experiment 1 : Comparison of Different Depth of Networks
|Model | Elapse Time | train_acc | train_loss | valid_acc | valid_loss |
|:----:|:-----------:|:---------:|:----------:|:---------:|:----------:|
|Depth 1| 9.18       |
|Depth 3| 14.15      |
|Depth 5| 19.27      |
|Depth 7| 24.23      |
|Depth 9| 29.10      |
## 2.1 Experiment 2 : Comparison of Different Width of Layers
## 2.1 Experiment 3 : Comparison of Different Loss Functions
## 2.1 Experiment 4 : Comparison of Different Activation Functions

## 3. Conclusion 



