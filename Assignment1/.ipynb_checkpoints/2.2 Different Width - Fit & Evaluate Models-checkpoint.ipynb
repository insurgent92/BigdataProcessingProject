{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visionnoob/anaconda3/envs/py36tf17/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import time\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "network1 = load_model('./models/mnist_width_1(no_trained).h5')\n",
    "network2 = load_model('./models/mnist_width_2(no_trained).h5')\n",
    "network3 = load_model('./models/mnist_width_3(no_trained).h5')\n",
    "network4 = load_model('./models/mnist_width_4(no_trained).h5')\n",
    "network5 = load_model('./models/mnist_width_5(no_trained).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 4s 73us/step - loss: 0.3235 - acc: 0.9063 - val_loss: 0.1422 - val_acc: 0.9603\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.1357 - acc: 0.9589 - val_loss: 0.0984 - val_acc: 0.9720\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0941 - acc: 0.9723 - val_loss: 0.0930 - val_acc: 0.9753\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0710 - acc: 0.9779 - val_loss: 0.0870 - val_acc: 0.9742\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0562 - acc: 0.9832 - val_loss: 0.0751 - val_acc: 0.9782\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0451 - acc: 0.9862 - val_loss: 0.0710 - val_acc: 0.9813\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0370 - acc: 0.9887 - val_loss: 0.0905 - val_acc: 0.9773\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0304 - acc: 0.9905 - val_loss: 0.0753 - val_acc: 0.9810\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0245 - acc: 0.9921 - val_loss: 0.0767 - val_acc: 0.9830\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.0746 - val_acc: 0.9813\n",
      "start_time 1525112998.0779088\n",
      "--- 14.309093713760376 seconds ---\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 1s 24us/step - loss: 0.2665 - acc: 0.9204 - val_loss: 0.1109 - val_acc: 0.9652\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 0.1036 - acc: 0.9682 - val_loss: 0.0883 - val_acc: 0.9763\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 0.0679 - acc: 0.9788 - val_loss: 0.0853 - val_acc: 0.9755\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0487 - acc: 0.9848 - val_loss: 0.0728 - val_acc: 0.9770\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 0.0376 - acc: 0.9879 - val_loss: 0.0840 - val_acc: 0.9782\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0284 - acc: 0.9910 - val_loss: 0.0743 - val_acc: 0.9815\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0222 - acc: 0.9926 - val_loss: 0.0947 - val_acc: 0.9790\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.0873 - val_acc: 0.9807\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 1s 22us/step - loss: 0.0130 - acc: 0.9955 - val_loss: 0.1074 - val_acc: 0.9805\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 1s 21us/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0953 - val_acc: 0.9808\n",
      "start_time 1525113012.387078\n",
      "--- 11.928711891174316 seconds ---\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.2344 - acc: 0.9278 - val_loss: 0.0859 - val_acc: 0.9740\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.0851 - acc: 0.9735 - val_loss: 0.0855 - val_acc: 0.9743\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.0550 - acc: 0.9826 - val_loss: 0.0705 - val_acc: 0.9823\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.0391 - acc: 0.9883 - val_loss: 0.1165 - val_acc: 0.9723\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.0304 - acc: 0.9905 - val_loss: 0.0812 - val_acc: 0.9802\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.0231 - acc: 0.9926 - val_loss: 0.0831 - val_acc: 0.9818\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.0895 - val_acc: 0.9808\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.0149 - acc: 0.9957 - val_loss: 0.1008 - val_acc: 0.9788\n",
      "Epoch 9/10\n",
      "20736/54000 [==========>...................] - ETA: 0s - loss: 0.0114 - acc: 0.9968"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "result1 = network1.fit(train_images, train_labels, epochs= 10, batch_size=128, validation_split = 0.1)\n",
    "print(\"start_time\", start_time)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))\n",
    "\n",
    "start_time = time.time() \n",
    "result2 = network2.fit(train_images, train_labels, epochs= 10, batch_size=128, validation_split = 0.1)\n",
    "print(\"start_time\", start_time)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))\n",
    "\n",
    "start_time = time.time() \n",
    "result3 = network3.fit(train_images, train_labels, epochs= 10, batch_size=128, validation_split = 0.1)\n",
    "print(\"start_time\", start_time)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))\n",
    "\n",
    "start_time = time.time() \n",
    "result4 = network4.fit(train_images, train_labels, epochs= 10, batch_size=128, validation_split = 0.1)\n",
    "print(\"start_time\", start_time)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))\n",
    "\n",
    "start_time = time.time() \n",
    "result5 = network5.fit(train_images, train_labels, epochs= 10, batch_size=128, validation_split = 0.1)\n",
    "print(\"start_time\", start_time)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.save('./models/mnist_width_1.h5')\n",
    "network2.save('./models/mnist_width_2.h5')\n",
    "network3.save('./models/mnist_width_3.h5')\n",
    "network4.save('./models/mnist_width_4.h5')\n",
    "network5.save('./models/mnist_width_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1_test_loss, n1_test_acc = network1.evaluate(test_images, test_labels)\n",
    "print('n1_test_acc:', n1_test_acc)\n",
    "print('n1_test_loss:', n1_test_loss)\n",
    "\n",
    "n2_test_loss, n2_test_acc = network2.evaluate(test_images, test_labels)\n",
    "print('n2_test_acc:', n2_test_acc)\n",
    "print('n2_test_loss:', n2_test_loss)\n",
    "\n",
    "n3_test_loss, n3_test_acc = network3.evaluate(test_images, test_labels)\n",
    "print('n3_test_acc:', n3_test_acc)\n",
    "print('n3_test_loss:', n3_test_loss)\n",
    "\n",
    "n4_test_loss, n4_test_acc = network4.evaluate(test_images, test_labels)\n",
    "print('n4_test_acc:', n4_test_acc)\n",
    "print('n4_test_loss:', n4_test_loss)\n",
    "\n",
    "n5_test_loss, n5_test_acc = network5.evaluate(test_images, test_labels)\n",
    "print('n5_test_acc:', n5_test_acc)\n",
    "print('n5_test_loss:', n5_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flotResult(data1,data2,data3,data4,data5):\n",
    "    plt.figure(figsize=(5,5))\n",
    "   \n",
    "\n",
    "\n",
    "    plt.plot(data1,'r', label='Depth_1')\n",
    "    plt.plot(data2,'g', label='Depth_3')\n",
    "    plt.plot(data3,'b', label='Depth_5')\n",
    "    plt.plot(data4,'c', label='Depth_7')\n",
    "    plt.plot(data5,'m', label='Depth_19')\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flotResult(result1.history['loss'], result2.history['loss'],result3.history['loss'],result4.history['loss'],result5.history['loss'])\n",
    "flotResult(result1.history['val_loss'], result2.history['val_loss'],result3.history['val_loss'],result4.history['val_loss'],result5.history['val_loss'])\n",
    "flotResult(result1.history['acc'], result2.history['acc'],result3.history['acc'],result4.history['acc'],result5.history['acc'])\n",
    "flotResult(result1.history['val_acc'], result2.history['val_acc'],result3.history['val_acc'],result4.history['val_acc'],result5.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
