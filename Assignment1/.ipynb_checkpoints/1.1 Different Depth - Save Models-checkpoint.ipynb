{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import models\n",
    "from keras import layers\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Set model 1\n",
    "\\# of layers : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = models.Sequential()\n",
    "network1.add(layers.Dense(10, activation='softmax', input_shape=(28 * 28,)))\n",
    "\n",
    "network1.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Set model 2\n",
    "\\# of layers : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = models.Sequential()\n",
    "network2.add(layers.Dense(16, activation='relu', input_shape=(28 * 28,)))\n",
    "network2.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network2.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network2.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Set model 3\n",
    "\\# of layers : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network3 = models.Sequential()\n",
    "network3.add(layers.Dense(16, activation='relu', input_shape=(28 * 28,)))\n",
    "network3.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network3.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network3.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network3.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network3.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Set model 4\n",
    "1. \\# of layers : 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network4 = models.Sequential()\n",
    "network4.add(layers.Dense(16, activation='relu', input_shape=(28 * 28,)))\n",
    "network4.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network4.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network4.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network4.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network4.add(layers.Dense(16, activation='relu', input_shape=(512,)))\n",
    "network4.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network4.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set model 5\n",
    "1. \\# of layers : 9\n",
    "\n",
    "2. \\# of units per layer : 16\n",
    "\n",
    "3. loss function : MSE\n",
    "\n",
    "4. activation function : relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network5 = models.Sequential()\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(28 * 28,)))\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network5.add(layers.Dense(16, activation='relu', input_shape=(16,)))\n",
    "network5.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network5.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MY CUSTUM CALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.accs = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accs.append(logs.get('acc'))   \n",
    "    \n",
    "batch_history1 = LossHistory()\n",
    "batch_history2 = LossHistory()\n",
    "batch_history3 = LossHistory()\n",
    "batch_history4 = LossHistory()\n",
    "batch_history5 = LossHistory()\n",
    "\n",
    "tb_hist1 = keras.callbacks.TensorBoard(log_dir='./graph/1', histogram_freq=0, write_graph=True, write_images=True)\n",
    "tb_hist2 = keras.callbacks.TensorBoard(log_dir='./graph/2', histogram_freq=0, write_graph=True, write_images=True)\n",
    "tb_hist3 = keras.callbacks.TensorBoard(log_dir='./graph/3', histogram_freq=0, write_graph=True, write_images=True)\n",
    "tb_hist4 = keras.callbacks.TensorBoard(log_dir='./graph/4', histogram_freq=0, write_graph=True, write_images=True)\n",
    "tb_hist5 = keras.callbacks.TensorBoard(log_dir='./graph/5', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_MAp = network1.fit(train_images, train_labels, epochs= 20, batch_size=32, validation_split = 0.1, callbacks=[batch_history1, tb_hist1])\n",
    "result_MAp = network2.fit(train_images, train_labels, epochs= 20, batch_size=32, validation_split = 0.1, callbacks=[batch_history2, tb_hist2])\n",
    "result_MAp = network3.fit(train_images, train_labels, epochs= 20, batch_size=32, validation_split = 0.1, callbacks=[batch_history3, tb_hist3])\n",
    "result_MAp = network4.fit(train_images, train_labels, epochs= 20, batch_size=32, validation_split = 0.1, callbacks=[batch_history4, tb_hist4])\n",
    "result_MAp = network5.fit(train_images, train_labels, epochs= 20, batch_size=32, validation_split = 0.1, callbacks=[batch_history5, tb_hist5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result_MAp.history['acc'])\n",
    "plt.plot(result_MAp.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network1.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network2.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network3.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network4.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network5.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
