{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visionnoob/anaconda3/envs/py36tf17/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2568 images belonging to 2 classes.\n",
      "Found 32 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split = 0.2)\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(validation_split = 0.013, preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "#categorical\n",
    "#binary\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'small_dataset/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        subset = 'training')\n",
    "\n",
    "vali_generator = train_datagen.flow_from_directory(\n",
    "        'small_dataset/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        subset = 'validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'small_dataset/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "#model.add(layers.Dense(2, activation = 'softmax'))\n",
    "model.add(layers.Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 16,812,610\n",
      "Trainable params: 2,097,922\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "#categorical_crossentropy\n",
    "#binary_crossentropy\n",
    "#mySGD = keras.optimizers.SGD(lr=0.1, momentum=0.99, decay=0.0, nesterov=False)\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=mySGD,\n",
    "  #            metrics=['acc'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "callback_func = keras.callbacks.RemoteMonitor(root='http://localhost:9000', path='/publish/epoch/end/', field='data', headers=None, send_as_json=False)\n",
    "tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=40,\n",
    "        epochs=20, callbacks =[callback_func])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=30, \n",
    "        validation_data = vali_generator,\n",
    "        validation_steps=50, callbacks =[callback_func, tb_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 4.9517 - acc: 0.6883\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 2.2072 - acc: 0.8612\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 1.5897 - acc: 0.9000\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 1.8887 - acc: 0.8823\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 1.8402 - acc: 0.8853\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 1.5169 - acc: 0.9048\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 1.7080 - acc: 0.8930\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 1.5705 - acc: 0.9020\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 14s 145ms/step - loss: 1.7469 - acc: 0.8915\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 1.7852 - acc: 0.8880\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 1.2783 - acc: 0.9200\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 1.0807 - acc: 0.9320\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 1.7636 - acc: 0.8900\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 1.3023 - acc: 0.9190\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 1.0216 - acc: 0.9365\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 1.0896 - acc: 0.9318\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 1.2883 - acc: 0.9195\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 1.3858 - acc: 0.9135\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 1.3930 - acc: 0.9135\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 1.1919 - acc: 0.9253\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 1.0302 - acc: 0.9355\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 1.6561 - acc: 0.8973\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 1.1767 - acc: 0.9270\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 1.4075 - acc: 0.9123\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 1.0870 - acc: 0.9310\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.9671 - acc: 0.9400\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 1.0114 - acc: 0.9373\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.9388 - acc: 0.9418\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 1.1445 - acc: 0.9290\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.9993 - acc: 0.9380\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_VALUE = np.array([103.939, 116.779, 123.68])   # BGR\n",
    "def preprocess(img):\n",
    "    # img is (channels, height, width), values are 0-255\n",
    "    img = img[...,::-1]  # switch to BGR\n",
    "    img -= MEAN_VALUE\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'n02088094_7.JPEG'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess(x)\n",
    "#x = preprocess_input(x)\n",
    "yhat = model.predict(x)\n",
    "print(x[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
